# TECHNICAL DEEP DIVE - Giáº£i thÃ­ch ká»¹ thuáº­t chi tiáº¿t
## DÃ nh cho pháº§n há»i Ä‘Ã¡p technical

---

## ğŸ” 1. REAL-ESRGAN ALGORITHM

### 1.1. Architecture Overview
```
Input (RGB Image)
    â†“
[Feature Extraction]
    â€¢ First Conv: 3 â†’ 64 channels
    â†“
[23 RRDB Blocks]
    â€¢ Residual-in-Residual Dense Block
    â€¢ Each block: 3 dense layers
    â€¢ Feature channels: 64
    â€¢ Growth channels: 32
    â†“
[Upsampling]
    â€¢ 2x: 1 PixelShuffle layer
    â€¢ 4x: 2 PixelShuffle layers
    â†“
[Final Conv]
    â€¢ 64 â†’ 3 channels (RGB)
    â†“
Output (Upscaled Image)
```

### 1.2. RRDB Block Detail
```
Input
  â”‚
  â”œâ”€[Dense Block]â”€â”€â”€â”€â”€â”€â”
  â”‚   â”œâ”€Convâ”€ReLU      â”‚
  â”‚   â”œâ”€Convâ”€ReLU      â”‚ (3 layers)
  â”‚   â””â”€Conv           â”‚
  â”‚                    â”‚
  â”œâ”€[Skip Connection]â”€â”€â”˜
  â”‚   Î² Ã— output
  â”‚
  â””â”€[Final Skip]
      Î± Ã— input + output
```

**Parameters:**
- Î² (beta) = 0.2 (residual scaling)
- Î± (alpha) = 0.2 (main skip scaling)

### 1.3. Training Strategy (tá»« paper)
- **Dataset:** DIV2K, Flickr2K, OutdoorScene
- **Degradation:** Real-world simulation
  - Blur (various kernels)
  - Resize
  - Noise (Gaussian, Poisson)
  - JPEG compression
  - Unsharp masking
- **Loss Function:**
  - L1 Loss
  - Perceptual Loss (VGG features)
  - GAN Loss (adversarial)
- **Optimizer:** Adam
- **Learning rate:** 1e-4 â†’ 1e-7 (cosine annealing)

### 1.4. Táº¡i sao Real-ESRGAN tá»‘t?
1. **Pure synthetic training** â†’ khÃ´ng cáº§n paired data
2. **Second-order degradation** â†’ realistic
3. **High-order degradation modeling** â†’ robust
4. **USM (Unsharp Masking)** â†’ sharper results

---

## ğŸ§® 2. NON-LOCAL MEANS DENOISING

### 2.1. Algorithm Principle
```python
# Pseudo-code
for each pixel p in image:
    for each pixel q in search_window:
        # Compare patches
        patch_p = get_patch(p, template_size)
        patch_q = get_patch(q, template_size)

        # Compute similarity weight
        weight = exp(-||patch_p - patch_q||Â² / hÂ²)

        # Weighted average
        denoised[p] += weight * image[q]

    denoised[p] /= sum(weights)
```

### 2.2. Parameters Explained
- **h (filter strength):**
  - Small (5-10): Ãt nhiá»…u, giá»¯ details
  - Medium (10-20): Balance
  - Large (20-30): Nhiá»u nhiá»…u, cÃ³ thá»ƒ blur

- **templateWindowSize (7):**
  - KÃ­ch thÆ°á»›c patch Ä‘á»ƒ so sÃ¡nh
  - Pháº£i lÃ  sá»‘ láº» (3, 5, 7, 9)
  - 7 lÃ  optimal cho most cases

- **searchWindowSize (21):**
  - VÃ¹ng tÃ¬m kiáº¿m patches tÆ°Æ¡ng tá»±
  - Lá»›n hÆ¡n â†’ cháº­m hÆ¡n nhÆ°ng tá»‘t hÆ¡n
  - 21 lÃ  good tradeoff

### 2.3. Complexity
- **Time:** O(N Ã— M Ã— TÂ²)
  - N: sá»‘ pixels
  - M: search window size
  - T: template size
- **Space:** O(N)

### 2.4. Æ¯u/NhÆ°á»£c Ä‘iá»ƒm
**Æ¯u Ä‘iá»ƒm:**
- âœ… KhÃ´ng cáº§n training
- âœ… Báº£o toÃ n edges tá»‘t
- âœ… Works on CPU
- âœ… Robust vá»›i nhiá»u loáº¡i noise

**NhÆ°á»£c Ä‘iá»ƒm:**
- âŒ Slow (vÃ i giÃ¢y cho 2K image)
- âŒ KhÃ´ng tá»‘t cho structured noise
- âŒ Over-smoothing náº¿u h quÃ¡ lá»›n

---

## ğŸ§© 3. TILING STRATEGY

### 3.1. Problem
```
Image size: 4096 Ã— 4096 Ã— 3 = 48 MB
After 4x upscale: 16384 Ã— 16384 Ã— 3 = 768 MB
GPU memory: Only 4-8 GB available
```

### 3.2. Solution: Tiling
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Original Image (4096x4096)     â”‚
â”‚                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ T1  â”‚ T2  â”‚ T3  â”‚ T4  â”‚    â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¤    â”‚
â”‚  â”‚ T5  â”‚ T6  â”‚ T7  â”‚ T8  â”‚    â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¤    â”‚
â”‚  â”‚ T9  â”‚ T10 â”‚ T11 â”‚ T12 â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜    â”‚
â”‚     â†‘                          â”‚
â”‚     â””â”€ Each tile: 512x512      â”‚
â”‚        Overlap: 64px           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.3. Implementation Details
```python
def tile_image(image, tile_size=512, overlap=64):
    """
    Split image into overlapping tiles
    """
    h, w = image.shape[:2]
    stride = tile_size - overlap

    tiles = []
    positions = []

    for y in range(0, h, stride):
        for x in range(0, w, stride):
            # Extract tile
            y_end = min(y + tile_size, h)
            x_end = min(x + tile_size, w)

            tile = image[y:y_end, x:x_end]
            tiles.append(tile)
            positions.append((y, x, y_end, x_end))

    return tiles, positions

def merge_tiles(tiles, positions, output_shape, overlap=64):
    """
    Merge tiles with blending in overlap regions
    """
    output = np.zeros(output_shape)
    weight_map = np.zeros(output_shape[:2])

    # Create feathering mask
    fade = create_fade_mask(tile_size, overlap)

    for tile, (y, x, y_end, x_end) in zip(tiles, positions):
        # Apply feathering
        tile_weighted = tile * fade

        # Add to output
        output[y:y_end, x:x_end] += tile_weighted
        weight_map[y:y_end, x:x_end] += fade

    # Normalize
    output /= weight_map[..., None]

    return output
```

### 3.4. Feathering (Blending)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Tile 1    â”‚    Tile 2       â”‚
â”‚           â”‚                 â”‚
â”‚      â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”            â”‚
â”‚      â”‚ Overlap â”‚            â”‚
â”‚      â”‚  Zone   â”‚            â”‚
â”‚      â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜            â”‚
â”‚           â”‚                 â”‚
â”‚      Blend with             â”‚
â”‚      linear interpolation   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Weight transition:
Tile 1: 1.0 â†’ 0.5 â†’ 0.0
Tile 2: 0.0 â†’ 0.5 â†’ 1.0
```

### 3.5. Memory Calculation
```
Without tiling:
- Input: 4096Ã—4096Ã—3 = 48 MB
- After 4x: 16384Ã—16384Ã—3 = 768 MB
- Intermediate: ~2 GB
- Total: ~3 GB VRAM

With tiling (512Ã—512):
- Per tile input: 512Ã—512Ã—3 = 0.75 MB
- Per tile output: 2048Ã—2048Ã—3 = 12 MB
- Model weights: ~60 MB
- Total: ~100 MB VRAM per tile
```

**Benefit:** CÃ³ thá»ƒ xá»­ lÃ½ áº£nh unlimited size vá»›i fixed memory!

---

## ğŸ’¾ 4. CHECKPOINT SYSTEM

### 4.1. Why Checkpointing?
**Problems solved:**
1. **OOM (Out of Memory):** Resume tá»« bÆ°á»›c trÆ°á»›c OOM
2. **Crash/Interrupt:** KhÃ´ng máº¥t cÃ´ng xá»­ lÃ½
3. **Debugging:** Kiá»ƒm tra output tá»«ng bÆ°á»›c
4. **Experimentation:** Test different configs tá»« checkpoint

### 4.2. Storage Format
```python
# Checkpoint structure
checkpoint_data = {
    'image': np.ndarray,        # Processed image
    'metadata': {
        'original_size': tuple,
        'is_grayscale': bool,
        'resize_factor': float,
        'step': str               # 'preprocessed', 'denoised', 'sr'
    },
    'timestamp': float,           # Unix timestamp
    'config': dict               # Config used
}

# File naming
checkpoint_name = f"{image_id}_{step}.pkl"
# Example: "photo123_preprocessed.pkl"
```

### 4.3. Resume Logic
```python
def restore_with_resume(image_path, resume=True):
    steps = ['preprocessed', 'denoised', 'sr']
    image = None

    # Find latest checkpoint
    for step in steps:
        if resume and checkpoint_exists(image_path, step):
            image, metadata = load_checkpoint(image_path, step)
            start_from = steps.index(step) + 1
            break

    # Continue from checkpoint or start fresh
    if image is None:
        image = preprocess(image_path)
        save_checkpoint(image, 'preprocessed')
        start_from = 1

    # Continue remaining steps
    for i in range(start_from, len(steps)):
        image = process_step(image, steps[i])
        save_checkpoint(image, steps[i])

    return image
```

### 4.4. Trade-offs
**Pros:**
- âœ… Resumable
- âœ… Debuggable
- âœ… Fault-tolerant

**Cons:**
- âŒ Disk space (má»—i checkpoint ~50-200 MB)
- âŒ I/O overhead (save/load time)
- âŒ Pickle security concerns

**Alternatives:**
- **NumPy:** `np.savez_compressed()` - safe, compressed
- **HDF5:** `h5py` - efficient, structured
- **Memory-mapped:** `np.memmap()` - zero-copy

---

## ğŸ§  5. MEMORY MANAGEMENT

### 5.1. Memory Lifecycle
```
Timeline: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’

Memory   â†‘
Usage    â”‚     â”Œâ”€Modelâ”€â”
         â”‚     â”‚       â”‚
         â”‚  â”Œâ”€â”€â”˜       â””â”€â”€â” â† Clear cache
         â”‚  â”‚             â”‚
         â”‚  â”‚    Process  â”‚
         â”‚  â”‚             â”‚
         â”œâ”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’
         0  Load        Unload           Time

Peak: During model inference
Base: After cleanup
```

### 5.2. PyTorch Memory Model
```python
# PyTorch allocates memory in 2 ways:

1. ALLOCATED (Active memory)
   - Currently used tensors
   - Model weights

2. RESERVED (Cached memory)
   - Previously allocated but freed
   - Kept for reuse (faster)
   - Not returned to system

# Our solution:
torch.cuda.empty_cache()  # Free cached memory
gc.collect()              # Python garbage collection
```

### 5.3. Memory Tracking
```python
def log_memory():
    if torch.cuda.is_available():
        allocated = torch.cuda.memory_allocated() / 1e9
        reserved = torch.cuda.memory_reserved() / 1e9
        print(f"Allocated: {allocated:.2f}GB")
        print(f"Reserved: {reserved:.2f}GB")
```

### 5.4. Memory Optimization Techniques
**1. Lazy Loading:**
```python
# Bad: Load all models upfront
model1 = load_model1()
model2 = load_model2()
process(model1, model2)

# Good: Load only when needed
model1 = None
model2 = None

def get_model1():
    if model1 is None:
        model1 = load_model1()
    return model1
```

**2. Immediate Unloading:**
```python
# Process with model
model = load_model()
result = model.process(image)

# Unload immediately
del model
torch.cuda.empty_cache()
```

**3. FP16 Inference:**
```python
# FP32 (default): 4 bytes per param
model_fp32 = load_model().float()  # ~240 MB

# FP16 (half): 2 bytes per param
model_fp16 = load_model().half()   # ~120 MB

# 50% memory saving!
# Quality loss: <1% for most tasks
```

**4. Gradient Disabled:**
```python
# Training mode (tracks gradients)
with torch.no_grad():           # Inference mode
    output = model(input)       # No gradient tracking
                                # ~40% memory saving
```

---

## ğŸ›ï¸ 6. CONFIGURATION SYSTEM

### 6.1. Why YAML?
**Pros:**
- âœ… Human-readable
- âœ… Comments supported
- âœ… Hierarchical structure
- âœ… Language-agnostic
- âœ… Git-friendly

**Cons:**
- âŒ No type checking (giáº£i quyáº¿t: validation)
- âŒ Indentation-sensitive

### 6.2. Validation Strategy
```python
@dataclass
class Config:
    def validate(self) -> bool:
        errors = []

        # Range validation
        if not 1 <= strength <= 100:
            errors.append(f"Invalid strength: {strength}")

        # Enum validation
        if type not in ["opencv", "nafnet"]:
            errors.append(f"Invalid type: {type}")

        # Dependency validation
        if tile_overlap >= tile_size:
            errors.append("Overlap must < tile_size")

        # Raise if errors
        if errors:
            raise ConfigurationError("\n".join(errors))

        return True
```

### 6.3. Configuration Precedence
```
1. Command-line args (highest priority)
   â””â”€ python main.py --scale 2

2. Environment variables
   â””â”€ export IMP_SCALE=2

3. Config file (YAML)
   â””â”€ config.yaml: scale: 2

4. Default values (lowest priority)
   â””â”€ @dataclass default values
```

### 6.4. Alternative: Pydantic
```python
from pydantic import BaseModel, Field, validator

class DenoisingConfig(BaseModel):
    type: str = Field(..., regex="^(opencv|nafnet)$")
    strength: int = Field(10, ge=1, le=100)

    @validator('strength')
    def validate_strength(cls, v):
        if v < 1 or v > 100:
            raise ValueError("Must be 1-100")
        return v

# Automatic validation!
# Type conversion!
# Better error messages!
```

---

## ğŸš¨ 7. ERROR HANDLING STRATEGY

### 7.1. Exception Hierarchy
```
Exception (built-in)
    â”‚
    â””â”€â”€ IMPError (custom base)
            â”‚
            â”œâ”€â”€ ConfigurationError
            â”‚   â”œâ”€ Invalid config values
            â”‚   â”œâ”€ Missing config file
            â”‚   â””â”€ Validation failed
            â”‚
            â”œâ”€â”€ ModelLoadError
            â”‚   â”œâ”€ Weights not found
            â”‚   â”œâ”€ Download failed
            â”‚   â”œâ”€ Library not installed
            â”‚   â””â”€ GPU not available
            â”‚
            â”œâ”€â”€ ProcessingError
            â”‚   â”œâ”€ Image load failed
            â”‚   â”œâ”€ Invalid format
            â”‚   â”œâ”€ Corruption detected
            â”‚   â””â”€ Processing failed
            â”‚
            â””â”€â”€ OutOfMemoryError
                â”œâ”€ GPU OOM
                â”œâ”€ RAM exhausted
                â””â”€ Image too large
```

### 7.2. Error Handling Pattern
```python
def process_image(image_path):
    try:
        # Attempt processing
        image = load_image(image_path)
        result = model.process(image)
        return result

    except OutOfMemoryError as e:
        # Specific handling for OOM
        logger.error(f"OOM: {e}")
        suggestions = [
            "Reduce tile_size to 256",
            "Use 2x instead of 4x",
            "Skip super-resolution"
        ]
        raise ProcessingError(
            f"Out of memory. Try: {suggestions}"
        ) from e

    except ModelLoadError as e:
        # Specific handling for model errors
        logger.error(f"Model error: {e}")
        raise

    except ProcessingError as e:
        # General processing errors
        logger.error(f"Processing failed: {e}")
        raise

    except Exception as e:
        # Unexpected errors
        logger.critical(f"Unexpected: {e}", exc_info=True)
        raise ProcessingError(
            f"Unexpected error: {e}"
        ) from e
```

### 7.3. Retry Logic
```python
def process_with_retry(image_path, max_retries=2):
    for attempt in range(max_retries + 1):
        try:
            return process_image(image_path)

        except OutOfMemoryError as e:
            if attempt < max_retries:
                # Try with smaller settings
                config.tile_size //= 2
                logger.warning(
                    f"OOM - Retry {attempt+1}/{max_retries} "
                    f"with tile_size={config.tile_size}"
                )
                clear_checkpoints()  # Fresh start
                continue
            else:
                raise

        except ProcessingError as e:
            if attempt < max_retries:
                logger.warning(
                    f"Failed - Retry {attempt+1}/{max_retries}"
                )
                continue
            else:
                raise
```

---

## ğŸ§ª 8. TESTING STRATEGY

### 8.1. Test Types
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Testing Pyramid                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                 â”Œâ”€â”€â”€â”€â”€â”€â”                â”‚
â”‚                 â”‚ E2E  â”‚  â† Few         â”‚
â”‚                 â””â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚             â”‚ Integration  â”‚  â† Some    â”‚
â”‚             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚         â”‚    Unit Tests        â”‚  â† Manyâ”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 8.2. Unit Test Examples
```python
# test_preprocessing.py
def test_smart_resize():
    # Arrange
    image = np.ones((4096, 4096, 3))
    preprocessor = Preprocessor(max_size=2048)

    # Act
    resized, scale = preprocessor.smart_resize(image)

    # Assert
    assert resized.shape == (2048, 2048, 3)
    assert scale == 0.5

def test_grayscale_detection():
    # True grayscale
    gray = np.ones((100, 100, 3)) * 128
    assert detect_grayscale(gray) == True

    # Color image
    color = np.random.rand(100, 100, 3) * 255
    assert detect_grayscale(color) == False
```

### 8.3. Integration Test
```python
# test_pipeline.py
def test_full_pipeline():
    # Arrange
    pipeline = OldPhotoRestoration()
    test_image = "test_data/noisy_lowres.jpg"

    # Act
    output = pipeline.restore(test_image)

    # Assert
    assert output is not None
    assert output.shape[0] > 0  # Has height
    assert output.shape[1] > 0  # Has width
    assert output.shape[2] == 3  # RGB
    assert output.min() >= 0
    assert output.max() <= 1
```

### 8.4. Mock Usage
```python
from unittest.mock import Mock, patch

def test_model_loading():
    # Mock model loading (no actual weights)
    with patch('src.models.super_resolution.RealESRGANer') as mock:
        mock_instance = Mock()
        mock.return_value = mock_instance

        # Test
        model = SuperResolutionModule()
        model.load_model()

        # Verify
        mock.assert_called_once()
```

---

## ğŸ“Š 9. PERFORMANCE ANALYSIS

### 9.1. Profiling Results
```
Function                    Calls   Time(s)   %Total
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
preprocess                      1      0.5      2.6%
  â”œâ”€ load_image                 1      0.3      1.6%
  â”œâ”€ detect_grayscale           1      0.1      0.5%
  â””â”€ smart_resize               1      0.1      0.5%

denoise                         1      3.0     15.8%
  â””â”€ fastNlMeans                1      2.9     15.3%

super_resolution                1     15.5     81.6%
  â”œâ”€ model_forward             16     14.0     73.7%  â† 16 tiles
  â””â”€ merge_tiles                1      1.5      7.9%
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOTAL                                 19.0    100.0%
```

### 9.2. Bottleneck Analysis
**Main bottleneck:** Super-resolution (81.6%)
- Model inference: 73.7%
- Tile merging: 7.9%

**Optimization opportunities:**
1. **Model quantization** (INT8) â†’ 2-3x faster
2. **TensorRT** optimization â†’ 2x faster
3. **Batch inference** â†’ 1.5x faster
4. **Multi-GPU** â†’ linear speedup

### 9.3. Memory Profile
```
Step              Peak Memory    Avg Memory
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Preprocessing          150 MB        100 MB
Denoising              300 MB        250 MB
Super-resolution     3,500 MB      2,000 MB  â† Peak
Post-processing        200 MB        150 MB
```

---

## ğŸ“ 10. KEY LEARNINGS

### 10.1. Technical Lessons
1. **Lazy loading is powerful** - Giáº£m 70% memory
2. **Tiling enables scalability** - Process unlimited size
3. **FP16 is a good trade-off** - 50% memory, <1% quality loss
4. **Checkpoints are critical** - Resume saves hours
5. **Error handling improves UX** - User-friendly messages

### 10.2. Software Engineering
1. **Type hints prevent bugs** - Caught 30+ bugs early
2. **Tests save time long-term** - Debug faster
3. **Documentation = Code** - Future self thanks you
4. **Modular design pays off** - Easy to extend
5. **Configuration is powerful** - Flexible without code changes

### 10.3. Challenges Overcome
1. **OOM errors** â†’ Tiling strategy
2. **Slow processing** â†’ Lazy loading + FP16
3. **Crashes** â†’ Checkpoint system
4. **Maintainability** â†’ Design patterns
5. **Debugging** â†’ Comprehensive logging

---

**Nhá»› ká»¹ nhá»¯ng Ä‘iá»ƒm nÃ y Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i technical!** ğŸ¯
